{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y8kjAmr5uG3",
        "outputId": "53052bd7-3541-4ade-ed2d-8b975508fc5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "\n",
        "# Baixar o dataset\n",
        "path = kagglehub.dataset_download(\"arifmia/animal\")\n",
        "\n",
        "# Caminho para o diretório raiz do dataset\n",
        "dataset_path = path + \"/Dataset/train/\"\n",
        "output_path = \"./data/\"\n",
        "print(\"Dataset baixado:\", path)\n",
        "\n",
        "\n",
        "\n",
        "for class_name in [\"cat\", \"dog\"]:\n",
        "    os.makedirs(os.path.join(output_path, class_name), exist_ok=True)\n",
        "    src_dir = os.path.join(dataset_path, class_name)\n",
        "    dest_dir = os.path.join(output_path, class_name)\n",
        "    for img_file in os.listdir(src_dir)[:200]:  # Pegando apenas 200 imagens\n",
        "        shutil.copy(os.path.join(src_dir, img_file), dest_dir)\n",
        "\n",
        "# Função para redimensionar imagens\n",
        "def resize_images(class_dir):\n",
        "    for img_file in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_file)\n",
        "        try:\n",
        "            img = load_img(img_path, target_size=(224, 224))  # Redimensiona\n",
        "            img.save(img_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {img_path}: {e}\")\n",
        "\n",
        "for class_name in [\"cat\", \"dog\"]:\n",
        "    resize_images(os.path.join(output_path, class_name))\n",
        "\n",
        "# Carregar o modelo treinado\n",
        "modelo = load_model(\"./models/trained_model.keras\")\n",
        "\n",
        "# Testar imagens e gerar matriz de confusão\n",
        "y_true, y_pred = [], []\n",
        "categories = [\"cat\", \"dog\"]\n",
        "\n",
        "for class_index, class_name in enumerate(categories):\n",
        "    for img_file in os.listdir(os.path.join(output_path, class_name)):\n",
        "        img_path = os.path.join(output_path, class_name, img_file)\n",
        "\n",
        "        img = load_img(img_path, target_size=(224, 224))\n",
        "        img_array = np.expand_dims(img_to_array(img) / 255.0, axis=0)\n",
        "\n",
        "        predicted_class = np.argmax(modelo.predict(img_array), axis=1)[0]\n",
        "        y_true.append(class_index)\n",
        "        y_pred.append(predicted_class)\n",
        "\n",
        "# Criar Matriz de Confusão\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=categories, yticklabels=categories)\n",
        "plt.xlabel(\"Classe Predita\")\n",
        "plt.ylabel(\"Classe Real\")\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n",
        "\n",
        "# Cálculo de Métricas\n",
        "VP, FP = conf_matrix[0]\n",
        "FN, VN = conf_matrix[1]\n",
        "\n",
        "sensibilidade = VP / (VP + FN) if (VP + FN) else 0\n",
        "acuracia = (VP + VN) / conf_matrix.sum() if conf_matrix.sum() else 0\n",
        "precisao = VP / (VP + FP) if (VP + FP) else 0\n",
        "f1_score = 2 * (precisao * sensibilidade) / (precisao + sensibilidade) if (precisao + sensibilidade) else 0\n",
        "\n",
        "# Exibir resultados\n",
        "print(f\"Sensibilidade (Recall): {sensibilidade:.2f}\")\n",
        "print(f\"Acurácia: {acuracia:.2f}\")\n",
        "print(f\"Precisão: {precisao:.2f}\")\n",
        "print(f\"F1-Score: {f1_score:.2f}\")\n",
        "\n",
        "# Gerar Curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, marker='o', linestyle='-', color='b', label=\"Curva ROC\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label=\"Linha Aleatória\")\n",
        "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YpAJbY934Qk1",
        "outputId": "7ce7f0f7-b662-4c0f-b50d-917aaf4a7faf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/arifmia/animal?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 440M/440M [00:07<00:00, 65.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset baixado: /root/.cache/kagglehub/datasets/arifmia/animal/versions/1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=trained_model.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9f8745cc365b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Carregar o modelo treinado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained_model.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Testar imagens e gerar matriz de confusão\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=trained_model.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ]
    }
  ]
}